{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, sys\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from scipy.fftpack import fft,ifft\n",
    "import matplotlib.pyplot as plt\n",
    "## Imports: Keras Models\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Lambda\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Cropping2D\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "### Imports: data preprocessing \n",
    "import csv\n",
    "import numpy as np\n",
    "import os\n",
    "import sklearn\n",
    "\n",
    "sf = 250.\n",
    "# Path for category 1\n",
    "young_task_path = \"/home/birdfly/Data/task/task young/\"\n",
    "# Path for category 2\n",
    "young_non_task_path = \"/home/birdfly/Data/task/non task young/\"\n",
    "\n",
    "freq_from = 0\n",
    "freq_to = 20\n",
    "\n",
    "channels_count = 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_directory(young_task_path, young_non_task_path):\n",
    "    \"\"\" \n",
    "        read all of the file under task_path\n",
    "        :param list task_path : path contains all of the files\n",
    "        :category task 0 or non task 1\n",
    "        return a list\n",
    "    \"\"\"\n",
    "    # task_datas = []\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    for sub_path in os.listdir(young_task_path):\n",
    "        task_data_files_paths = glob.glob(os.path.join(young_task_path, sub_path) + \"/*.csv\")\n",
    "        for task_data_files_path in task_data_files_paths:\n",
    "            data = pd.read_csv(task_data_files_path, sep=',')\n",
    "            data_req = transfer_time_to_freq(data)\n",
    "            X_train.append(data_req)\n",
    "            y_train.append(0)\n",
    "\n",
    "    for sub_path in os.listdir(young_non_task_path):\n",
    "        task_data_files_paths = glob.glob(os.path.join(young_non_task_path, sub_path) + \"/*.csv\")\n",
    "        for task_data_files_path in task_data_files_paths:\n",
    "            data = pd.read_csv(task_data_files_path, sep=',')\n",
    "            data_req = transfer_time_to_freq(data)\n",
    "            X_train.append(data_req)\n",
    "            y_train.append(1)\n",
    "            \n",
    "    X_train = np.asarray(X_train)\n",
    "    y_train = tf.keras.utils.to_categorical(y=y_train, num_classes=2)\n",
    "    \n",
    "    return X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_time_to_freq(data, freq_from = freq_from, freq_to = freq_to):\n",
    "    freq_data = []\n",
    "    for row_index in data:  \n",
    "        fft_y=fft(data[row_index])\n",
    "        T = 1/250.  # sampling interval \n",
    "        N = data[row_index].size\n",
    "        # 1/T = frequency\n",
    "        f = np.linspace(0, 1 / T, N)\n",
    "        freq_data_row = np.abs(fft_y)[:N // 2] * 1 / N\n",
    "        freq_data.extend(freq_data_row[freq_from:freq_to])\n",
    "    \n",
    "    freq_data_t = pd.DataFrame(freq_data).T.values.tolist()\n",
    "    return freq_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(x_train, y_train, x_test, y_test):\n",
    "    \"\"\"\n",
    "        run deep learning network and save trained model\n",
    "        :param func train_generator\n",
    "        :param func validation_generator\n",
    "    \"\"\"\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense((freq_to - freq_from)*channels_count, activation='relu'),\n",
    "        tf.keras.layers.Dense(chanel_count, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.05),\n",
    "        tf.keras.layers.Dense((freq_to - freq_from), activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.05),\n",
    "        tf.keras.layers.Dense(2, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "    model.fit(x_train, y_train, epochs= 10)\n",
    "    model.evaluate(x_test, y_test)\n",
    "    \n",
    "    model.save('model.h5')\n",
    "    print('model.h5 has been saved.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if __name__ == \"__main__\":\n",
    "    x, y = read_directory(young_task_path, young_non_task_path)\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split( x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    run_model(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if name == \"main\": x, y = read_directory(young_task_path, young_non_task_path)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split( x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "run_model(x_train, y_train, x_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
